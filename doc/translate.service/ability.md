translate.service 它提供将大模型或其他机器翻译转化为标准文本翻译接口，可能第一感觉，错误的理解为，它只是去询问大模型，然后以接口的形式暴露出来。这里进行详细罗列了它做了哪方面的优化。


# **1. 大模型优化**
## **1.1 多模型接入** 
统一接口遵循，可接入多个完全不同的大模型，提供自定义约束及结果处理定义，比如当前已接入的 OpenAI、Ollama、GiteeAI.. 等不同的大模型及调用方式，以及 qwen3、glm、DeepSeek、gemma3、hunyun-mt、seed-X 等不同的大模
## **1.2 提示词适配** 
自动根据不同的大模型，匹配不同的提示词，进行翻译。比如当前已接入的 qwen3、glm、DeepSeek、gemma3、hunyun-mt、seed-X 等不同的大模型，它们的提示词不同，需要根据不同的大模型，匹配不同的提示词、不同的temperature、top_k... 等参数。
## **1.3 多重自检修复**
### **1.3.1 max_tokens自动处理** 
根据翻译的原文，自动预测结果集，设置 max_tokens 参数，避免文本生成时循环陷阱导致tokens被大量消耗、时长被拉大
### **1.3.2 结果预处理** 
对大模型返回的翻译结果，会进行预处理，根据翻译的原文跟译文进行对比，去除一些不合规的字符、以及对大模型结果进行修复处理，保障翻译质量。
### **1.3.3 上下文理解偏差方面优化** 
在进行翻译时，大模型会存在一些不确定性及处理偶然的处理异常， 比如要翻译 '你好世界,你有多大' 大模型翻译为英文后为： 'Hello world, how 大 are you' 这里面的 '大' 没有被正常翻译，translate.service 会自动识别并对漏翻译的文本进行修复翻译，以保证翻译的稳定。
### **1.3.4 译文质量打分** 
对译文跟原文进行打分，根据不同的权重进行排定，出一个最终分数，以此判断翻译是否准确。如果分数过低，会自动启动修复机制介入，保障翻译质量。
### **1.3.5 注意力机制方面优化** 
比如原文是疑问句时，结果译文成了答案的情况，比如翻译 '你是谁' 翻译为 英语后变成了 'my name is' ，这时候就需要对结果进行修复，将其修正为 'who are you' 。
### **1.3.6 文本生成中的循环陷阱处理** 
比如中文翻译为阿拉伯语时，出现无限循环、无标点输出的现象，模型生成失控的现象
### **1.3.7 推理结果处理** 
如果使用了推理模型，并启用了推理能力，则会对推理模型的结果进行处理，只保留翻译的译文。
### **1.3.8 大模型结果修复** 
对于大模型输出的结果，会进行格式自检，自动进行修复格式，保证其结果一致，能被程序进行自动化处理。
### **1.3.9 标点符号的一致性** 
对于大模型输出的结果，进行标点符号的预处理，对原文及译文的标点符号进行一致性效验，比如原文是 '你好世界' 翻译为英语后大模型输出 'Hello world.' 会自动将其修正为 'Hello world' ，保持与原文的标点符号一致。
### **1.3.10 大模型进行翻译结果的语义检测** 
可配置是否使用大模型进行翻译结果的语义检测？以验证原文跟译文是否匹配 。 可通过配置文件 config.properties 中的 translate.service.set.useSemanticsModelApi 进行配置是否启用。

## **1.4 翻译文本预处理机制** 
比如要翻译的文本中带有巨量的特殊字符、不规则杂乱字符、各种html标签等，会给大模型造成识别困难、输出结果错乱、译文跟原文无法保证一致性等诸多问题。 以下可通过配置文件 config.properties 中的 text.split 进行精准配置哪一项是否启用
### **1.4.1 长文本断句处理** 
针对中文、日语、韩语、粤语、拉丁文(英法意大利西班牙葡萄牙...)、等语种体系，对长文本进行自动识别并断句，将长文本切分成多个短句，每个短句进行多线程翻译提速，同时保障其语义的通畅完整。 
### **1.4.2 网址识别保持** 
针对网址进行识别处理，保证网址的完整性，不会因为翻译时将网址内的部分文字翻译而导致网址失效。
### **1.4.3 邮箱识别保持**  
针对邮箱进行识别处理，保证邮箱的完整性，不会因为翻译时将邮箱内的部分文字翻译而导致邮箱失效。
### **1.4.4 文件名识别保持**  
针对文件名进行识别处理，保证文件名的完整性，不会因为翻译时将文件名内的部分文字翻译而导致文件名无法正常阅读。
### **1.4.5 HTML标签识别保持**  
针对HTML标签进行识别处理，保证HTML标签的完整性，不会因为翻译时将HTML标签进行翻译而导致标签不完整
### **1.4.6 空白符处理保持**  
针对换行符、制表符、空格等空白符进行识别处理，保证空白符的完整性，传入了什么格式的空白符，翻译完后得到的依旧是什么符都有，保证翻译前后特殊空白符的一致性
### **1.4.7 无意义文本识别** 
针对无意义、不具备翻译能力的文本提前识别处理，比如 'NO123' ，不会误翻译使其表述内容发生改变。
### **1.4.8 分词分析能力** 
对文本分词、语种识别、分析（分析一个翻译文本出现的语种、语种分布、文本长度、文本复杂度等）。
### **1.4.9 token预处理** 
对一段文本进行token处理，识别文本中的token数量，以及每个token的长度。

## **1.5 多模型混用及自动调度机制** 
正常翻译有尺寸较小的模型提供介入翻译，当翻译质量不足时，有尺寸较大的模型进行介入翻译及修复，最大化提高翻译速度、降低翻译成本。
### **1.5.1 正常翻译通道** 
翻译将先经过此通道进行正常翻译，若翻译出现异常、或质量自检不达标，将自动有修复通道进行介入修复。 可通过配置文件 config.properties 中的 translate.service.xxx 进行配置正常翻译通道相关。
### **1.5.2 修复通道** 
当正常翻译通道翻译出现异常、或质量自检不达标时，将自动有修复通道进行介入修复。修复通道的模型尺寸一般要大于正常翻译通道的模型尺寸，以保障质量。 可通过配置文件 config.properties 中的 translate.service.set.repair.service、 translate.service.set.repair.config 进行配置修复通道相关。
### **1.5.3 备用通道** 
如果正常翻译通道、修复通道后都无法正常翻译、或翻译质量不达标时，将自动有备用通道进行介入翻译。备用通道的模型尺寸一般要大于正常翻译通道的模型尺寸，以保障质量。也或者有 translate100 提供支持，保证能翻译出结果。 可通过配置文件 config.properties 中的 translate.service.standby.service、translate.service.standby.config 进行配置备用通道相关。
### **1.6 大模型线程池** 
普通使用大模型进行处理时，大模型具有反应慢、耗时长等缺点。此为大模型多线程模式加速翻译，通过对文本预处理、分词后，多线程并行加速，极大提高翻译速度。比如输出速度为 50字/秒，那翻译100个句子，每个句子50个字，你需要 100 秒才能拿到翻译结果。而如果开启了 translate.service 的线程池的能力，启用多线程线程能力的话，只需要1秒，即可得到翻译结果。
#### **1.6.1 最大线程数** 
可通过配置文件 config.properties 中的 translate.service.set.threadNumber 进行配置线程池中，最大的线程数。线程数越多，加速也快。
#### **1.6.2 允许使用的最大并发数百分比** 
大模型允许使用的最大并发数百分比。如果使用翻译接口时，需要通过大模型翻译，而当前大模型的实际并发数超过设置的最大并发数 (translate.service.set.threadNumber) 百分之多少时，就不在去使用大模型了，而是直接返回一个翻译服务忙碌的失败提示，避免产生任务堆积。 可通过配置文件 config.properties 中的 translate.service.thread.apiPercentageIntercept 进行配置
#### **1.6.3 最大的等待线程数** 
大模型翻译所使用的 最大的等待线程数。比如 translate.service.set.threadNumber 设置的是 100，允许同时最大可以有100个大模型请求， 当一次翻译传递了 150 个要翻译的文本时，其中会有100个进行大模型请求，剩下 50 个进入等待阶段，当前面的100个其中有哪个请求完毕后才会陆续执行在等待阶段的50个请求。  这个配置项，便是当线程池满了，等待阶段的翻译文本（请求数）超过多少时，就不允许再加了，避免异常情况产生大量的等待线程堆积。  
可通过配置文件 config.properties 中的 translate.service.thread.waitThreadNumber 进行配置
#### **1.6.4 实时日志输出** 
当使用大模型进行翻译时，是否在控制台打印有关线程池当前使用数的日志。可通过配置文件 config.properties 中的 translate.service.thread.threadDebug 进行配置

## **1.7 完全私有化部署** 
可以在无网络环境下进行部署，无需依赖外外网资源，即可进行翻译服务。这里支持一些开源免费的大模型提供翻译支持
### **1.7.1 大模型翻译**
#### **1.7.1.1 超低配硬件支持** 
比如你如果硬件配置很低，比如单纯就是1核2G的机器无GPU显卡，也能部署 https://huggingface.co/xnx3/translate100 它是一个用于翻译任务的 seq-to-seq 架构、基于 Transformer 的神经机器翻译模型，支持完整及量化运行，支持100个语种的翻译，只不过翻译质量相对较弱。它一般作为备用模型通道，当正常模型翻译出现异常时，它会自动启用备份模型进行翻译。
#### **1.7.1.2 高质量翻译** 
可以接入 Seed-X、hunyun-mt 等 7B 大模型，提供三十余个语种的高质量翻译，这几个大模型都是开源免费的，可直接部署后接入 translate.service 进行使用。
#### **1.7.1.3 多语种高质量翻译** 
如果需要支持比较多的语种，可以接入 qwen3-30B-A3B 大模型进行提供翻译，支持百多个语种的翻译，翻译质量非常不错。 如果硬件较低，也可以使用 qwen3-8B 、 qwen3-4B ,只不过尺寸小了翻译质量会打折扣。
### **1.7.2 机器翻译** 
你还可以接入传统机器翻译，提供翻译支持
#### **1.7.3 LibreTranslate** 
是一个开源的神经网络机器翻译，支持几十种语种的翻译。你可以直接部署后接入 translate.service 进行使用。它可以在2核4G的服务器即可稳定运行，对硬件要求低
#### **1.7.4 小牛翻译** 
它支离线私有部署的小牛翻译接入。小牛翻译支持五百多个语种，基本你想要的语种，小牛翻译都支持。

# **2. 开放接口API** 
## **2.1 管理的API接口** 
### **2.1.1 系统相关**
#### **2.1.1.1 获取系统当前状态** 
接口  /admin/system/status.json 可获取当前系统版本号、请求线程池状态、等待线程数、JVM内存使用、GC情况数据等
#### **2.1.1.2 重启服务器** 
接口  /admin/system/reboot.json 可触发重启服务器操作
#### **2.1.1.3 自动配置SSL证书** 
接口  /admin/install/openSsl.json 无需任何人工干预，全自动完成SSL证书的申请、绑定、续期等操作。
### **2.1.2 大模型相关** 
跟开源中国GiteeAI联合开发深度整合，更方便使用

#### **2.1.2.1 大模型余额查询** 
接口  /admin/giteeAI/app/user 获取当前接入的大模型giteeAI的信息，比如当前剩余的大模型调用余额等。
#### **2.1.2.2 大模型余额充值** 
接口  /admin/giteeAI/accountRecharge.html 大模型余额充值
### **2.1.3 域名白名单管理** 
可以管理允许哪些域名使用，而不在白名单中的域名，将不允许使用。还可以开通 api key ，通过 api key 可以通过标准http api 的方式调用文本翻译接口进行使用。
#### **2.1.3.1 设置域名/key** 
接口  /admin/domain/setDomain.json 设置使用翻译能力的域名或key , 还可以设置每个域名或key的使用内存缓存大小、文件缓存大小、翻译通道...
#### **2.1.3.2 获取域名/key** 
接口  /admin/domain/getDomainList.json 获取当前设置的域名或key的信息，支持全部列出、精准搜索、模糊搜索 等多种方式
#### **2.1.3.3 删除域名/key** 
接口  /admin/domain/deleteDomain.json  删除当前已经设置过的，使用翻译能力的域名或key
#### **2.1.3.4 删除域名/key** 
接口  /admin/domain/getDomainStatus.json 获取这个域名当前的状态。主要是一些统计数据，比如当前的调用次数、当前使用的内存缓存所存储的字符数大小、文件缓存所存储的字符数、当日使用的翻译字符数、命中文件缓存的翻译字符数、命中内存缓存的翻译字符数 等。
### **2.1.4 缓存管理** 
#### **2.1.4.1 从缓存获取数据** 
接口  /admin/cache/getCache.json 获取缓存中的数据。比如获取某天某个网站翻译了多少字符、使用了多大的内存存储、磁盘空间缓存占用了多大、翻译时多少字符是命中缓存的、多少字符是通过翻译接口或大模型的、哪个文本翻译成某个语种后是翻译为了什么...
#### **2.1.4.2 清空缓存** 
接口  /admin/cache/clear.json 清空当前所有的缓存数据。
#### **2.1.4.3 清除文件缓存** 
接口  /admin/cache/clearFileCache.json 清空当前所有的文件缓存的数据。
#### **2.1.4.4 设置缓存中文本的翻译结果** 
接口  /admin/cache/setCacheText.json 用于对缓存中的文本进行设置翻译结果。比如之前进行过翻译，翻译了文本 '你好' 翻译为英语，大模型或机器翻译将其翻译为 'Hello' ，但是你不想让他返回这个结果，可以通过此接口，进行指定 '你好' 翻译为 英语 的结果为 'NiHao' ，那么你这个域名/key之后再进行翻译时，它将会成为 'NiHao' 而不是 'Hello' 。 (这个是直接翻译 '你好'，而不是 '你好世界' 产生包含)
#### **2.1.4.5 获取缓存中文本的翻译结果** 
接口  /admin/cache/getCacheText.json 精确获取，不是模糊匹配获取
#### **2.1.4.6 获取缓存中文本的翻译结果列表** 
接口  /admin/cache/getCacheTextList.json 模糊匹配获取，返回列表。比如你之前翻译过 '你好' 翻译过英语、法语、俄语 ，那这个返回的列表中，'你好' 这一项它会将所有翻译过的英语、法语、俄语的翻译结果都返回。

## **2.2 用户的开放API接口** 
### **2.2.1 健康检查** 
接口  /index.do 它无任何功能性作用，仅仅只是用来做健康检查而已。他会检查初始化是否异常、数据是否准确、翻译通道是否通畅、大模型请求线程池状态是否正常、缓存是否正常、GC状态是否正常、JVM是否正常等。
### **2.2.2 测速检查** 
接口  /connectTest.json 连接测试，测试接口是否能访问通，以及请求响应时间。它的作用是，用户通过浏览器打开网页时，会自动触发多个测速，取响应最快的测速域名，进行翻译服务接入。
### **2.2.3 获取当前支持的语言** 
接口  /language.json 不同的翻译通道、不同的大模型、不同的机器翻译能力所提供的语言支持也不同，这里根据当前的配置，返回当前支持的语言列表。
### **2.2.4 文本翻译接口** 
接口  /translate.json 提供文本翻译的功能。用户通过调用此接口，传入要翻译的文本、目标语种，即可获取翻译结果。它将各种大模型、机器翻译、翻译平台自动转化为统一的翻译接口进行使用

# **3. 日志体系** 
翻译日志、运行日志、流控日志、修复日志、备用通道日志、请求日志 等等，都会进行详细记录。 他们存放在 /mnt/service/logs/ 目录下
## **3.1 大模型正常通道使用日志** 
qwen3_yyyy-MM-dd.log 是调用大模型进行文本翻译的日志，其中 qwen3 是大模型名字。 它记录了你所有文本翻译的原文、译文、进行时间、翻译结果审查得分、是否启用了修复机制 等
## **3.2 大模型修复通道日志** 
bigmodel_repair_yyyy-MM-dd.log 是修复通道的日志。它记录了修复通道的翻译内容、翻译结果、修复时间、修复结果等。
## **3.3 大模型备用通道日志** 
standbyService_yyyy-MM-dd.log 是备用通道的日志。它记录了备用通道的翻译内容、翻译结果、翻译时间、翻译结果等。
## **3.4 大模型正常通道失败的日志** 
qwen3_first_score_failure_yyyy-MM-dd.log 是大模型正常通道翻译失败的日志。接口请求异常、翻译质量不足、打分不达标... 等，凡是大模型正常通道翻译失败的情况，都会记录到这个日志文件中。
## **3.5 系统运行日志** 
translate.service.log 是系统运行日志，它存放 translate.service 本身的运行情况的日志
## **3.6 访问请求日志** 
request_yyyy-MM-dd.log 是进行翻译请求（/translate.json）的请求日志。它并不是你访问后它就会立即产生日志，而是它有一个日志缓冲，比如当日志达到几百条、或者距离上次将其保存到日志文件超过 2 分钟，它才会进行将日志信息打包写入到日志文件中，以便在高并发场景时，减轻磁盘IO压力。
## **3.7 访问拦截日志** 
requestControl_yyyy-MM-dd.log 是进行翻译请求（/translate.json）的请求拦截日志。当某个用户端请求速度过快，触发了流控策略时，会将该请求拦截下来，阻止这个请求使用翻译能力。阻止的请求会记录到该日志文件中，将此次的域名/key、浏览器信息、ip信息、等终端信息进行记录。

# **4. 统计功能** 
针对 域名/key 进行统计其翻译相关
## **4.1 某日翻译字符数** 
可以统计其每日翻译的字符数
## **4.2 某日翻译命中内存缓存的字符数** 
可以统计其每日翻译命中内存缓存的字符数。命中内存缓存的，将不会再走大模型或机器翻译，直接从内存缓存中获取翻译结果。提高响应速度，降低资源消耗
## **4.3 某日翻译命中文件缓存的字符数** 
可以统计其每日翻译命中文件缓存的字符数。命中文件缓存的，将不会再走大模型或机器翻译，直接从文件缓存中获取翻译结果。提高响应速度，降低资源消耗
# **5. 内置H2数据库** 
内置H2数据库，用于存储翻译相关的文本历史。部署无需额外配置，即可直接使用。可进行检索历史翻译文本，查看原文跟译文情况及修改译文。可通过配置文件 config.properties 中的 database.use 进行配置是否启用
# **6. 域名白名单** 
域名/key 白名单，可以对每个域名/key 设置其限额，只有在白名单中的域名/key 才会允许通过接口进行翻译。如果不在白名单中的域名/key ，则会被拒绝翻译，以保护翻译接口的安全。
# **7. 两层翻译缓存** 
采用文件、内存 两层缓存，加快翻译响应，降低资源使用
## **7.1 文件缓存** 
采用文件缓存作为第一层翻译缓存，将有磁盘来承载，借助于磁盘超低价的优势，将翻译结果缓存到文件中，当有相同的翻译请求时，会先从文件缓存中获取翻译结果，若文件缓存中没有，则会走内存缓存。可通过配置文件 config.properties 中的 cache.file.use 进行配置是否启用。
## **7.2 内存缓存** 
采用内存缓存作为第二层翻译缓存，将有内存来承载，将翻译结果缓存到内存中，当有相同的翻译任务时，会从内存缓存中获取翻译结果，若内存缓存中没有，则会走大模型或机器翻译。可通过配置文件 config.properties 中的 cache.memory.use 进行配置是否启用。
# **8. 访问控制拦截** 
针对 translate.json 文本翻译API接口的请求次数控制，避免某个终端过快的调用翻译能力。比如 translate.js 使用时js写错导致循环掉接口、某个api使用方每秒上千次调用导致接口被恶意占用等。它可以对翻译接口的访问频次进行控制。
## **8.1 指定周期内最大请求次数** 
指定时间周期内最大允许请求次数，不设置默认是2次。可通过配置文件 config.properties 中的 request.control.translateJson.number.maxRequests 进行配置。
## **8.2 设置指定周期是多长** 
设置指定的时间周期是多长，不设置默认是2秒。可通过配置文件 config.properties 中的 request.control.translateJson.number.cycleTime 进行配置。
# **9. 语种分流策略**  
可以通过配置文件 config.properties 中的 translate.service.set.mainService 进行配置是否启用。可以指定哪几个语种是走主通道，除了这几个语种之外，其他的将不走主通道，而是自动走备用通道进行翻译。









